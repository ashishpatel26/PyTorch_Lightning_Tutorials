{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c06cf6e8",
      "metadata": {
        "id": "c06cf6e8",
        "papermill": {
          "duration": 0.004842,
          "end_time": "2022-08-15T07:38:11.808033",
          "exception": false,
          "start_time": "2022-08-15T07:38:11.803191",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "\n",
        "# Introduction to Pytorch Lightning\n",
        "\n",
        "* **Author:** PL team\n",
        "* **License:** CC BY-SA\n",
        "* **Generated:** 2022-08-15T09:28:49.859904\n",
        "\n",
        "In this notebook, we'll go over the basics of lightning by preparing models to train on the [MNIST Handwritten Digits dataset](https://en.wikipedia.org/wiki/MNIST_database).\n",
        "\n",
        "---\n",
        "Open in [![Open In Colab](data:image/png;base64,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){height=\"20px\" width=\"117px\"}](https://colab.research.google.com/github/PytorchLightning/lightning-tutorials/blob/publication/.notebooks/lightning_examples/mnist-hello-world.ipynb)\n",
        "\n",
        "Give us a â­ [on Github](https://www.github.com/PytorchLightning/pytorch-lightning/)\n",
        "| Check out [the documentation](https://pytorch-lightning.readthedocs.io/en/stable/)\n",
        "| Join us [on Slack](https://www.pytorchlightning.ai/community)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e2fd17",
      "metadata": {
        "id": "50e2fd17",
        "papermill": {
          "duration": 0.003993,
          "end_time": "2022-08-15T07:38:11.814891",
          "exception": false,
          "start_time": "2022-08-15T07:38:11.810898",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Setup\n",
        "This notebook requires some packages besides pytorch-lightning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "25d6a362",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-15T07:38:11.822333Z",
          "iopub.status.busy": "2022-08-15T07:38:11.821497Z",
          "iopub.status.idle": "2022-08-15T07:38:16.125962Z",
          "shell.execute_reply": "2022-08-15T07:38:16.124965Z"
        },
        "id": "25d6a362",
        "lines_to_next_cell": 0,
        "papermill": {
          "duration": 4.310742,
          "end_time": "2022-08-15T07:38:16.128255",
          "exception": false,
          "start_time": "2022-08-15T07:38:11.817513",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ! pip install --quiet \"pandas\" \"ipython[notebook]\" \"torchvision\" \"setuptools==59.5.0\" \"torch>=1.8\" \"torchmetrics>=0.7\" \"seaborn\" \"pytorch-lightning>=1.4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2d0b3468",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-15T07:38:16.135797Z",
          "iopub.status.busy": "2022-08-15T07:38:16.135237Z",
          "iopub.status.idle": "2022-08-15T07:38:21.149397Z",
          "shell.execute_reply": "2022-08-15T07:38:21.148489Z"
        },
        "id": "2d0b3468",
        "outputId": "71aa7a6c-08ba-45e8-d19c-90355ad1bcb8",
        "papermill": {
          "duration": 5.020155,
          "end_time": "2022-08-15T07:38:21.151455",
          "exception": false,
          "start_time": "2022-08-15T07:38:16.131300",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import torch\n",
        "from IPython.core.display import display\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchmetrics import Accuracy\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
        "BATCH_SIZE = 256 if torch.cuda.is_available() else 64"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3d202be",
      "metadata": {
        "id": "f3d202be",
        "lines_to_next_cell": 2,
        "papermill": {
          "duration": 0.002704,
          "end_time": "2022-08-15T07:38:21.157367",
          "exception": false,
          "start_time": "2022-08-15T07:38:21.154663",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Simplest example\n",
        "\n",
        "Here's the simplest most minimal example with just a training loop (no validation, no testing).\n",
        "\n",
        "**Keep in Mind** - A `LightningModule` *is* a PyTorch `nn.Module` - it just has a few more helpful features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b4006d34",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-15T07:38:21.164985Z",
          "iopub.status.busy": "2022-08-15T07:38:21.163865Z",
          "iopub.status.idle": "2022-08-15T07:38:21.169743Z",
          "shell.execute_reply": "2022-08-15T07:38:21.169093Z"
        },
        "id": "b4006d34",
        "papermill": {
          "duration": 0.011232,
          "end_time": "2022-08-15T07:38:21.171284",
          "exception": false,
          "start_time": "2022-08-15T07:38:21.160052",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class MNISTModel(LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = torch.nn.Linear(28 * 28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        x, y = batch\n",
        "        loss = F.cross_entropy(self(x), y)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.02)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f90796b",
      "metadata": {
        "id": "8f90796b",
        "papermill": {
          "duration": 0.003934,
          "end_time": "2022-08-15T07:38:21.178257",
          "exception": false,
          "start_time": "2022-08-15T07:38:21.174323",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "By using the `Trainer` you automatically get:\n",
        "1. Tensorboard logging\n",
        "2. Model checkpointing\n",
        "3. Training and validation loop\n",
        "4. early-stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3268802f",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b250fc528ad34540a8c799a8edcbcaa6"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-08-15T07:38:21.186850Z",
          "iopub.status.busy": "2022-08-15T07:38:21.186288Z",
          "iopub.status.idle": "2022-08-15T07:38:44.086018Z",
          "shell.execute_reply": "2022-08-15T07:38:44.085313Z"
        },
        "id": "3268802f",
        "outputId": "f4adf95e-f407-4fd7-acc2-054f4489feef",
        "papermill": {
          "duration": 22.906386,
          "end_time": "2022-08-15T07:38:44.087649",
          "exception": false,
          "start_time": "2022-08-15T07:38:21.181263",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to .\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8200d9b5ce6b44a3beaf592c7179facd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting .\\MNIST\\raw\\train-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to .\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34d2d1af6f124ae4932b26a00f3227a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting .\\MNIST\\raw\\train-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0d2e7c29ae34e8ca6e34f60ea496d16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36ef29e41c07439ba9d6043436d60db9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: d:\\Github\\PyTorch_Lightning_Tutorials\\Notebooks\\lightning_logs\n",
            "\n",
            "  | Name | Type   | Params\n",
            "--------------------------------\n",
            "0 | l1   | Linear | 7.9 K \n",
            "--------------------------------\n",
            "7.9 K     Trainable params\n",
            "0         Non-trainable params\n",
            "7.9 K     Total params\n",
            "0.031     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ibm26\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8bb4cf76a644e8db6cc320d4426e5b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        }
      ],
      "source": [
        "# Init our model\n",
        "mnist_model = MNISTModel()\n",
        "\n",
        "# Init DataLoader from MNIST Dataset\n",
        "train_ds = MNIST(PATH_DATASETS, train=True, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Initialize a trainer\n",
        "trainer = Trainer(\n",
        "    accelerator=\"auto\",\n",
        "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
        "    max_epochs=3,\n",
        "    callbacks=[TQDMProgressBar(refresh_rate=20)],\n",
        ")\n",
        "\n",
        "# Train the model âš¡\n",
        "trainer.fit(mnist_model, train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d68706b",
      "metadata": {
        "id": "2d68706b",
        "lines_to_next_cell": 2,
        "papermill": {
          "duration": 0.003345,
          "end_time": "2022-08-15T07:38:44.094709",
          "exception": false,
          "start_time": "2022-08-15T07:38:44.091364",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## A more complete MNIST Lightning Module Example\n",
        "\n",
        "That wasn't so hard was it?\n",
        "\n",
        "Now that we've got our feet wet, let's dive in a bit deeper and write a more complete `LightningModule` for MNIST...\n",
        "\n",
        "This time, we'll bake in all the dataset specific pieces directly in the `LightningModule`.\n",
        "This way, we can avoid writing extra code at the beginning of our script every time we want to run it.\n",
        "\n",
        "---\n",
        "\n",
        "### Note what the following built-in functions are doing:\n",
        "\n",
        "1. [prepare_data()](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#prepare-data) ðŸ’¾\n",
        "    - This is where we can download the dataset. We point to our desired dataset and ask torchvision's `MNIST` dataset class to download if the dataset isn't found there.\n",
        "    - **Note we do not make any state assignments in this function** (i.e. `self.something = ...`)\n",
        "\n",
        "2. [setup(stage)](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#setup) âš™ï¸\n",
        "    - Loads in data from file and prepares PyTorch tensor datasets for each split (train, val, test).\n",
        "    - Setup expects a 'stage' arg which is used to separate logic for 'fit' and 'test'.\n",
        "    - If you don't mind loading all your datasets at once, you can set up a condition to allow for both 'fit' related setup and 'test' related setup to run whenever `None` is passed to `stage` (or ignore it altogether and exclude any conditionals).\n",
        "    - **Note this runs across all GPUs and it *is* safe to make state assignments here**\n",
        "\n",
        "3. [x_dataloader()](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.core.hooks.DataHooks.html#pytorch_lightning.core.hooks.DataHooks.train_dataloader) â™»ï¸\n",
        "    - `train_dataloader()`, `val_dataloader()`, and `test_dataloader()` all return PyTorch `DataLoader` instances that are created by wrapping their respective datasets that we prepared in `setup()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d044c45e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-15T07:38:44.102843Z",
          "iopub.status.busy": "2022-08-15T07:38:44.102322Z",
          "iopub.status.idle": "2022-08-15T07:38:44.116414Z",
          "shell.execute_reply": "2022-08-15T07:38:44.115760Z"
        },
        "id": "d044c45e",
        "papermill": {
          "duration": 0.020071,
          "end_time": "2022-08-15T07:38:44.117930",
          "exception": false,
          "start_time": "2022-08-15T07:38:44.097859",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LitMNIST(LightningModule):\n",
        "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, learning_rate=2e-4):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Set our init args as class attributes\n",
        "        self.data_dir = data_dir\n",
        "        self.hidden_size = hidden_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Hardcode some dataset specific attributes\n",
        "        self.num_classes = 10\n",
        "        self.dims = (1, 28, 28)\n",
        "        channels, width, height = self.dims\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Define PyTorch model\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(channels * width * height, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_size, self.num_classes),\n",
        "        )\n",
        "\n",
        "        self.val_accuracy = Accuracy()\n",
        "        self.test_accuracy = Accuracy()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        self.val_accuracy.update(preds, y)\n",
        "\n",
        "        # Calling self.log will surface up scalars for you in TensorBoard\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        self.test_accuracy.update(preds, y)\n",
        "\n",
        "        # Calling self.log will surface up scalars for you in TensorBoard\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    ####################\n",
        "    # DATA RELATED HOOKS\n",
        "    ####################\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # download\n",
        "        MNIST(self.data_dir, train=True, download=True)\n",
        "        MNIST(self.data_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "\n",
        "        # Assign train/val datasets for use in dataloaders\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
        "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
        "\n",
        "        # Assign test dataset for use in dataloader(s)\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.mnist_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.mnist_val, batch_size=BATCH_SIZE)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.mnist_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e2be9463",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d8f9e9b32b8f46479efebbd2a82a90ea",
            "c2c31c5cad74431faa620232e62dc3c6",
            "7cd0f98adc9e4cbc817a2bbf7ff8fd6e",
            "90f26221f5aa4d9fad7efda328ee7872",
            "b50edce1334f431eaab470ec9592ca2c"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-08-15T07:38:44.130113Z",
          "iopub.status.busy": "2022-08-15T07:38:44.129645Z",
          "iopub.status.idle": "2022-08-15T07:39:18.947964Z",
          "shell.execute_reply": "2022-08-15T07:39:18.947221Z"
        },
        "id": "e2be9463",
        "outputId": "3933e9eb-c11a-4c01-a7c1-d5e17f60d5df",
        "papermill": {
          "duration": 34.824096,
          "end_time": "2022-08-15T07:39:18.949581",
          "exception": false,
          "start_time": "2022-08-15T07:38:44.125485",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: logs/lightning_logs\n",
            "\n",
            "  | Name          | Type       | Params\n",
            "---------------------------------------------\n",
            "0 | model         | Sequential | 55.1 K\n",
            "1 | val_accuracy  | Accuracy   | 0     \n",
            "2 | test_accuracy | Accuracy   | 0     \n",
            "---------------------------------------------\n",
            "55.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "55.1 K    Total params\n",
            "0.220     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "325cd40950aa45d1865ffa4ad7fb940d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ibm26\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1330a39244ef43cf9ee65b735876c4ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e0ccfc200334a27a35d4546270f0791",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11f8508a29b346c8a6c1d89c7a478cda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7947631f1320487ebb0d32a91cf53c39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        }
      ],
      "source": [
        "model = LitMNIST()\n",
        "trainer = Trainer(\n",
        "    accelerator=\"auto\",\n",
        "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
        "    max_epochs=3,\n",
        "    callbacks=[TQDMProgressBar(refresh_rate=20)],\n",
        "    logger=CSVLogger(save_dir=\"logs/\"),\n",
        ")\n",
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd635b38",
      "metadata": {
        "id": "dd635b38",
        "papermill": {
          "duration": 0.004346,
          "end_time": "2022-08-15T07:39:18.958411",
          "exception": false,
          "start_time": "2022-08-15T07:39:18.954065",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Testing\n",
        "\n",
        "To test a model, call `trainer.test(model)`.\n",
        "\n",
        "Or, if you've just trained a model, you can just call `trainer.test()` and Lightning will automatically\n",
        "test using the best saved checkpoint (conditioned on val_loss)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c408962a",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6364c95a14c6439b9d146e9678bbdcd5"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-08-15T07:39:18.967997Z",
          "iopub.status.busy": "2022-08-15T07:39:18.967629Z",
          "iopub.status.idle": "2022-08-15T07:39:20.800679Z",
          "shell.execute_reply": "2022-08-15T07:39:20.799929Z"
        },
        "id": "c408962a",
        "outputId": "0eb2bacc-d04d-4bf9-c861-efde93aad0e9",
        "papermill": {
          "duration": 1.840978,
          "end_time": "2022-08-15T07:39:20.803493",
          "exception": false,
          "start_time": "2022-08-15T07:39:18.962515",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ibm26\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1386: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
            "  rank_zero_warn(\n",
            "Restoring states from the checkpoint path at logs/lightning_logs\\version_0\\checkpoints\\epoch=2-step=2580.ckpt\n",
            "Loaded model weights from checkpoint at logs/lightning_logs\\version_0\\checkpoints\\epoch=2-step=2580.ckpt\n",
            "c:\\Users\\ibm26\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94b4f0ad0839466e963366adf26407ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "       Test metric             DataLoader 0\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "        test_acc            0.9437999725341797\n",
            "        test_loss           0.18427906930446625\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'test_loss': 0.18427906930446625, 'test_acc': 0.9437999725341797}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cfa5b0",
      "metadata": {
        "id": "c7cfa5b0",
        "papermill": {
          "duration": 0.004456,
          "end_time": "2022-08-15T07:39:20.812997",
          "exception": false,
          "start_time": "2022-08-15T07:39:20.808541",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Bonus Tip\n",
        "\n",
        "You can keep calling `trainer.fit(model)` as many times as you'd like to continue training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "11c15b6d",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "095e69aee4b94600aa62b3254319b657"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-08-15T07:39:20.824136Z",
          "iopub.status.busy": "2022-08-15T07:39:20.823685Z",
          "iopub.status.idle": "2022-08-15T07:39:21.093991Z",
          "shell.execute_reply": "2022-08-15T07:39:21.093269Z"
        },
        "id": "11c15b6d",
        "outputId": "b74cf141-cc1a-4b34-fef9-ad1648c00f6a",
        "papermill": {
          "duration": 0.278034,
          "end_time": "2022-08-15T07:39:21.095622",
          "exception": false,
          "start_time": "2022-08-15T07:39:20.817588",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ibm26\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:616: UserWarning: Checkpoint directory logs/lightning_logs\\version_0\\checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "\n",
            "  | Name          | Type       | Params\n",
            "---------------------------------------------\n",
            "0 | model         | Sequential | 55.1 K\n",
            "1 | val_accuracy  | Accuracy   | 0     \n",
            "2 | test_accuracy | Accuracy   | 0     \n",
            "---------------------------------------------\n",
            "55.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "55.1 K    Total params\n",
            "0.220     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "465f0d251a364af093ced3efc4e4dd11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5dc723e",
      "metadata": {
        "id": "c5dc723e",
        "papermill": {
          "duration": 0.004673,
          "end_time": "2022-08-15T07:39:21.105679",
          "exception": false,
          "start_time": "2022-08-15T07:39:21.101006",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "In Colab, you can use the TensorBoard magic function to view the logs that Lightning has created for you!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "047afaca",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-15T07:39:21.116914Z",
          "iopub.status.busy": "2022-08-15T07:39:21.116563Z",
          "iopub.status.idle": "2022-08-15T07:39:21.472331Z",
          "shell.execute_reply": "2022-08-15T07:39:21.471622Z"
        },
        "id": "047afaca",
        "outputId": "4fe2cd4e-0068-4042-f402-ae6cf39c93d7",
        "papermill": {
          "duration": 0.363582,
          "end_time": "2022-08-15T07:39:21.473935",
          "exception": false,
          "start_time": "2022-08-15T07:39:21.110353",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.300076</td>\n",
              "      <td>0.9132</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.237311</td>\n",
              "      <td>0.9304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.198669</td>\n",
              "      <td>0.9392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.184279</td>\n",
              "      <td>0.9438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       val_loss  val_acc  test_loss  test_acc\n",
              "epoch                                        \n",
              "0      0.300076   0.9132        NaN       NaN\n",
              "1      0.237311   0.9304        NaN       NaN\n",
              "2      0.198669   0.9392        NaN       NaN\n",
              "2           NaN      NaN   0.184279    0.9438"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x26b7e5b7b20>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 439.5x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
        "del metrics[\"step\"]\n",
        "metrics.set_index(\"epoch\", inplace=True)\n",
        "display(metrics.dropna(axis=1, how=\"all\").head())\n",
        "sn.relplot(data=metrics, kind=\"line\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "colab_type,colab,id,-all",
      "formats": "ipynb,py:percent",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 72.337649,
      "end_time": "2022-08-15T07:39:22.813197",
      "environment_variables": {},
      "exception": null,
      "input_path": "lightning_examples/mnist-hello-world/hello-world.ipynb",
      "output_path": ".notebooks/lightning_examples/mnist-hello-world.ipynb",
      "parameters": {},
      "start_time": "2022-08-15T07:38:10.475548",
      "version": "2.4.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "3fc1222195c38f3bacb3f86364a5ddd1a5f141dfc09ae13cca4287c10db1561a"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
